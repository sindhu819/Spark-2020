{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tensorflow]",
      "language": "python",
      "name": "conda-env-tensorflow-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "Copy of Spark-SQL2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sindhu819/Spark-2020/blob/main/Copy_of_Spark_SQL2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh5NCoc8fsSO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "b9ca166c-bed1-47c4-d6b8-9480e051bb94"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession,SQLContext, Row\n",
        "from operator import add, sub\n",
        "from time import sleep\n",
        "\n",
        "from pyspark.streaming import StreamingContext\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [75.1 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [6,781 B]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [761 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [32.7 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,322 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [794 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,057 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [10.5 kB]\n",
            "Hit:20 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:21 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:22 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,742 kB]\n",
            "Get:23 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [840 kB]\n",
            "Fetched 6,913 kB in 11s (639 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEb4HTRwiaJx"
      },
      "source": [
        "Congrats! Your Colab is ready to run Pyspark. \n",
        "\n",
        "# EDA\n",
        "\n",
        "We will use a Uber ride dataset for this exercise. Load the dataset into your Colab directory from your local system:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WbzJM4cYp1I"
      },
      "source": [
        "#1 Code to read csv file into colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubjxW9IrYrMG"
      },
      "source": [
        "#2. Get the file\n",
        "#make sure you upload all your data files to your Google drive and change share->Advanced->change->anyone with the link can view\n",
        "downloaded = drive.CreateFile({'id':'1M8WiN-TSMIBxTK-rSoKdkWdhS-nWKFJe'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('Uber-Jan-Feb-FOIL.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TyI8L1dAJyT"
      },
      "source": [
        "# read the csv file in as a Spark dataframe\n",
        "df = spark.read.csv('Uber-Jan-Feb-FOIL.csv',inferSchema=True, header =True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03bDu2DQk04_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1e8f52d4-8733-4c1f-f75f-17498dc61d16"
      },
      "source": [
        "#Let's preview 10 rows of data\n",
        "df.show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+--------+---------------+-----+\n",
            "|dispatching_base_number|    date|active_vehicles|trips|\n",
            "+-----------------------+--------+---------------+-----+\n",
            "|                 B02512|1/1/2015|            190| 1132|\n",
            "|                 B02765|1/1/2015|            225| 1765|\n",
            "|                 B02764|1/1/2015|           3427|29421|\n",
            "|                 B02682|1/1/2015|            945| 7679|\n",
            "|                 B02617|1/1/2015|           1228| 9537|\n",
            "|                 B02598|1/1/2015|            870| 6903|\n",
            "|                 B02598|1/2/2015|            785| 4768|\n",
            "|                 B02617|1/2/2015|           1137| 7065|\n",
            "|                 B02512|1/2/2015|            175|  875|\n",
            "|                 B02682|1/2/2015|            890| 5506|\n",
            "+-----------------------+--------+---------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgncUsN0lGUO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2df8c64-ca20-41a8-9d5b-ca30ab880f5e"
      },
      "source": [
        "#How many rows are in this dataset\n",
        "df.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "354"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3BU_j6-0Kpq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "166dc6eb-ad47-4e3a-d360-672b473329c2"
      },
      "source": [
        "len(df.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXKbo2MczISS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e4565b54-a1d3-4ec5-dcdf-2ff37cce8ece"
      },
      "source": [
        "# What's the column description?\n",
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- dispatching_base_number: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- active_vehicles: integer (nullable = true)\n",
            " |-- trips: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CsLl0zc0Rxr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a72e8bc1-c922-41d2-daf4-6fdbe7f6100c"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- dispatching_base_number: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- active_vehicles: integer (nullable = true)\n",
            " |-- trips: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AApUxE4ql0d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "37db307f-7cd5-4309-bb3c-a3ce845e5010"
      },
      "source": [
        "# Find out if there is any null values. If so, how many null values are present in each column?\n",
        " from pyspark.sql.functions import isnan, when, count, col \n",
        " df.select([count(when(isnan(c), c)).alias(c) for c in df.columns]).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+----+---------------+-----+\n",
            "|dispatching_base_number|date|active_vehicles|trips|\n",
            "+-----------------------+----+---------------+-----+\n",
            "|                      0|   0|              0|    0|\n",
            "+-----------------------+----+---------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BtHkgf7mCRy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "44352f92-a948-4a15-d116-e82fdd51c038"
      },
      "source": [
        "#How many, for each distinct data in the dispatching_base_number column, are there?\n",
        "df.groupby('dispatching_base_number').count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+-----+\n",
            "|dispatching_base_number|count|\n",
            "+-----------------------+-----+\n",
            "|                 B02512|   59|\n",
            "|                 B02598|   59|\n",
            "|                 B02682|   59|\n",
            "|                 B02765|   59|\n",
            "|                 B02617|   59|\n",
            "|                 B02764|   59|\n",
            "+-----------------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWqc6FKK0V1S"
      },
      "source": [
        "df.createOrReplaceTempView(\"uber\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYgUTJ-N0_Js",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "aad1ca47-7b1f-43b5-9e27-99cf38336638"
      },
      "source": [
        "spark.sql(\"select distinct(dispatching_base_number) as base, count(*) from uber group by (dispatching_base_number)\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------+\n",
            "|  base|count(1)|\n",
            "+------+--------+\n",
            "|B02682|      59|\n",
            "|B02598|      59|\n",
            "|B02512|      59|\n",
            "|B02764|      59|\n",
            "|B02765|      59|\n",
            "|B02617|      59|\n",
            "+------+--------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muyjRMIdzISY"
      },
      "source": [
        "# Register as table ready for Spark SQL \n",
        "df.registerTempTable(\"uber1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w9Ly2U4zISd"
      },
      "source": [
        "# Show with Spark SQL, what are the distinct values of dispatching_base_number?\n",
        "k=spark.sql(\"select distinct(dispatching_base_number) from uber\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNfnRybv19pT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b7f62d7d-6126-4410-adfb-a0d675f39c85"
      },
      "source": [
        "for i in k.collect():\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Row(dispatching_base_number='B02512')\n",
            "Row(dispatching_base_number='B02598')\n",
            "Row(dispatching_base_number='B02682')\n",
            "Row(dispatching_base_number='B02765')\n",
            "Row(dispatching_base_number='B02617')\n",
            "Row(dispatching_base_number='B02764')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNaOnfUk2K4K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8d386a4b-0e00-47e6-a144-92c5923857aa"
      },
      "source": [
        "spark.sql(\"select distinct(dispatching_base_number) from uber\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+\n",
            "|dispatching_base_number|\n",
            "+-----------------------+\n",
            "|                 B02512|\n",
            "|                 B02598|\n",
            "|                 B02682|\n",
            "|                 B02765|\n",
            "|                 B02617|\n",
            "|                 B02764|\n",
            "+-----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa5AiJVMqqQB"
      },
      "source": [
        "#### Show, for each distinct value of dispatching_base_number, the total number of trips made. Display the result from high to low with respect to the total number of trips made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu12677zzISh"
      },
      "source": [
        "result = spark.sql(\"\"\"select distinct(dispatching_base_number) as base,sum(trips) as cnt from uber group by dispatching_base_number order by cnt desc\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT91P371U4C6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c7f48ed2-3c5b-4fe6-c050-3b2083af99db"
      },
      "source": [
        "result.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+\n",
            "|  base|    cnt|\n",
            "+------+-------+\n",
            "|B02764|1914449|\n",
            "|B02617| 725025|\n",
            "|B02682| 662509|\n",
            "|B02598| 540791|\n",
            "|B02765| 193670|\n",
            "|B02512|  93786|\n",
            "+------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGfu_hYanGUK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e73f486c-ddcd-475b-9a1c-d84506097f3d"
      },
      "source": [
        "type(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGzxHp-sneVJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "78e2b454-b2c7-4d6a-b0fe-cf0c0990ed73"
      },
      "source": [
        "# Filter the above result and show only those with the total number of trips made greater than 700,000\n",
        "result.filter(result.cnt>700000).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+\n",
            "|  base|    cnt|\n",
            "+------+-------+\n",
            "|B02764|1914449|\n",
            "|B02617| 725025|\n",
            "+------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6itwPjicHQdp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d648fb77-250c-413c-82ea-ab83a4ce8beb"
      },
      "source": [
        "result.registerTempTable(\"result\")\n",
        "spark.sql(\"\"\"select * from result where cnt >700000\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+\n",
            "|  base|    cnt|\n",
            "+------+-------+\n",
            "|B02764|1914449|\n",
            "|B02617| 725025|\n",
            "+------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urb_bJdGck_h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "cf374ed0-f6ba-4e35-b369-7dfb39185b7d"
      },
      "source": [
        "# Repeat by using the Spark SQL\n",
        "result.registerTempTable(\"result\")\n",
        "spark.sql(\"\"\"select * from result where cnt >700000\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+\n",
            "|  base|    cnt|\n",
            "+------+-------+\n",
            "|B02764|1914449|\n",
            "|B02617| 725025|\n",
            "+------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAAxPU_vr5RC"
      },
      "source": [
        "####Show the total number of trips made for each distinct date.   \n",
        "####Dispay only the top 5 highest results of the total number of trips made and show the related date."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9MlY_rZzISj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f0b8ed0a-1fb3-449d-a1da-eea0ffc44790"
      },
      "source": [
        "spark.sql(\"\"\"select date ,sum(trips) as cnt from uber group by date order by cnt desc\"\"\").show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+------+\n",
            "|     date|   cnt|\n",
            "+---------+------+\n",
            "|2/20/2015|100915|\n",
            "|2/14/2015|100345|\n",
            "|2/21/2015| 98380|\n",
            "|2/13/2015| 98024|\n",
            "|1/31/2015| 92257|\n",
            "+---------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdp6ZWUpzISp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}