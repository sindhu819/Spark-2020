{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Copy of classification by Spark",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sindhu819/Spark-2020/blob/main/Copy_of_classification_by_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq8U3BtmhtRx"
      },
      "source": [
        "\n",
        "# **Running Pyspark inÂ Colab**\n",
        "\n",
        "To run spark in Colab, we need to first install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGg9D79Y90eu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "7626fe4d-1234-431a-e4cd-137cf02c43cd"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.88.173)] [1\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.88.173)] [W\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:2 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Ign:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [75.1 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,742 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [761 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,057 kB]\n",
            "Get:18 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [840 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [6,781 B]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [794 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [32.7 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [10.5 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,322 kB]\n",
            "Fetched 6,913 kB in 3s (2,611 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEb4HTRwiaJx"
      },
      "source": [
        "Congrats! Your Colab is ready to run Pyspark. \n",
        "\n",
        "# EDA\n",
        "\n",
        "The goal of this exercise to explore and analyze the Boston Housing dataset.   Load the dataset into your Colab directory from your local system:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WbzJM4cYp1I"
      },
      "source": [
        "#1 Code to read csv file into colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubjxW9IrYrMG"
      },
      "source": [
        "#2. Get the file\n",
        "#make sure you upload all your data files to your Google drive and change share->Advanced->change->anyone with the link can view\n",
        "downloaded = drive.CreateFile({'id':'1o8OH-hFyZxaCjxlSb2AtopjVaMdVmCLL'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('iris.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhIPPhLvrZ1m"
      },
      "source": [
        "## load iris data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTGttyzjrZ1n"
      },
      "source": [
        "iris = spark.read.csv('iris.csv', header=True, inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BVHJHlurZ1p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "53aa9b5e-ef25-455d-e04a-0ad98feaa599"
      },
      "source": [
        "iris.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+-----------+------------+-----------+-------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
            "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
            "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
            "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
            "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otv5OlQqrZ1s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "642901a4-61e8-418c-9425-7f3f03ddd4f4"
      },
      "source": [
        "iris.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sepal_length', 'double'),\n",
              " ('sepal_width', 'double'),\n",
              " ('petal_length', 'double'),\n",
              " ('petal_width', 'double'),\n",
              " ('species', 'string')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rXQSANhrZ1u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "37751879-d21e-4adb-c0cd-cf55fdb93411"
      },
      "source": [
        "iris.describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+-------------------+------------------+------------------+---------+\n",
            "|summary|      sepal_length|        sepal_width|      petal_length|       petal_width|  species|\n",
            "+-------+------------------+-------------------+------------------+------------------+---------+\n",
            "|  count|               150|                150|               150|               150|      150|\n",
            "|   mean| 5.843333333333335| 3.0540000000000007|3.7586666666666693|1.1986666666666672|     null|\n",
            "| stddev|0.8280661279778637|0.43359431136217375| 1.764420419952262|0.7631607417008414|     null|\n",
            "|    min|               4.3|                2.0|               1.0|               0.1|   setosa|\n",
            "|    max|               7.9|                4.4|               6.9|               2.5|virginica|\n",
            "+-------+------------------+-------------------+------------------+------------------+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsN1yBGqrZ1w"
      },
      "source": [
        "## Merge features to create a features column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw_VdFYfrZ1w"
      },
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql import Row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEmQ0JIKrZ1z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "cb13ac7e-2b26-49c0-f21f-35e0a3baf4cb"
      },
      "source": [
        "iris2 = iris.rdd.map(lambda x: Row(features=Vectors.dense(x[:-1]), species=x[-1])).toDF()\n",
        "iris2.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+-------+\n",
            "|         features|species|\n",
            "+-----------------+-------+\n",
            "|[5.1,3.5,1.4,0.2]| setosa|\n",
            "|[4.9,3.0,1.4,0.2]| setosa|\n",
            "|[4.7,3.2,1.3,0.2]| setosa|\n",
            "|[4.6,3.1,1.5,0.2]| setosa|\n",
            "|[5.0,3.6,1.4,0.2]| setosa|\n",
            "+-----------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSl1sPF4wp3w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "4ee52d9c-6b1a-47d1-d2bb-da54646ee909"
      },
      "source": [
        "iris2.groupBy('species').count().orderBy('species').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+\n",
            "|   species|count|\n",
            "+----------+-----+\n",
            "|    setosa|   50|\n",
            "|versicolor|   50|\n",
            "| virginica|   50|\n",
            "+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6R8UYs1f3yP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab8b0704-4b49-4f07-ec5d-abcced8bf3b4"
      },
      "source": [
        "iris2.select(\"species\").distinct().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmR1pJpsgomu"
      },
      "source": [
        "iris2.createOrReplaceTempView(\"iris\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj6ce8M7gt66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2f2676cd-35ed-4578-cf9c-df06e88f2bf8"
      },
      "source": [
        "spark.sql(\"select species,count(*) from iris group by species order by species\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+--------+\n",
            "|   species|count(1)|\n",
            "+----------+--------+\n",
            "|    setosa|      50|\n",
            "|versicolor|      50|\n",
            "| virginica|      50|\n",
            "+----------+--------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiykoDhtrZ11"
      },
      "source": [
        "## Index label column with `StringIndexer`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKmF8XuzrZ11"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-jzu62frZ12"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA-Ue-7srZ14"
      },
      "source": [
        "### Build pipeline\n",
        "Let's change the categorical species to numeric labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8wueHtJrZ14"
      },
      "source": [
        "stringindexer = StringIndexer(inputCol='species', outputCol='label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NqhH-exrZ16"
      },
      "source": [
        "### Transform data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frS_DxVxzGWe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3abc28c3-634e-49b3-fb81-a9397b2cac3a"
      },
      "source": [
        "iris_df = stringindexer.fit(iris2).transform(iris2)\n",
        "iris_df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+-------+-----+\n",
            "|         features|species|label|\n",
            "+-----------------+-------+-----+\n",
            "|[5.1,3.5,1.4,0.2]| setosa|  2.0|\n",
            "|[4.9,3.0,1.4,0.2]| setosa|  2.0|\n",
            "|[4.7,3.2,1.3,0.2]| setosa|  2.0|\n",
            "|[4.6,3.1,1.5,0.2]| setosa|  2.0|\n",
            "|[5.0,3.6,1.4,0.2]| setosa|  2.0|\n",
            "+-----------------+-------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbAwNxt8zrKC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "16c06cad-c054-4ec5-d814-a100704435ef"
      },
      "source": [
        "from pyspark.sql.functions import rand\n",
        "iris_df.orderBy(rand()).limit(10).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+----------+-----+\n",
            "|         features|   species|label|\n",
            "+-----------------+----------+-----+\n",
            "|[6.7,3.3,5.7,2.5]| virginica|  1.0|\n",
            "|[7.7,2.8,6.7,2.0]| virginica|  1.0|\n",
            "|[5.8,2.7,4.1,1.0]|versicolor|  0.0|\n",
            "|[4.9,3.1,1.5,0.1]|    setosa|  2.0|\n",
            "|[6.1,2.9,4.7,1.4]|versicolor|  0.0|\n",
            "|[5.8,4.0,1.2,0.2]|    setosa|  2.0|\n",
            "|[6.8,3.2,5.9,2.3]| virginica|  1.0|\n",
            "|[6.1,2.6,5.6,1.4]| virginica|  1.0|\n",
            "|[4.6,3.6,1.0,0.2]|    setosa|  2.0|\n",
            "|[6.4,2.8,5.6,2.2]| virginica|  1.0|\n",
            "+-----------------+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMHBjilprZ18"
      },
      "source": [
        "### Check the data one more time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hzHC19mrZ19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3344e962-120a-4a9b-8784-90f116f2251f"
      },
      "source": [
        "iris_df.describe().show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+---------+------------------+\n",
            "|summary|  species|             label|\n",
            "+-------+---------+------------------+\n",
            "|  count|      150|               150|\n",
            "|   mean|     null|               1.0|\n",
            "| stddev|     null|0.8192319205190403|\n",
            "|    min|   setosa|               0.0|\n",
            "|    max|virginica|               2.0|\n",
            "+-------+---------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qdQpx6FrZ1_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e315c111-8d9b-460d-9177-a5afd43845a7"
      },
      "source": [
        "iris_df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('features', 'vector'), ('species', 'string'), ('label', 'double')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg-lCIjtrZ2B"
      },
      "source": [
        "## Naive Bayes classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG8_oaZarZ2B"
      },
      "source": [
        "### Split data into training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WH6LfGCrZ2C"
      },
      "source": [
        "train, test = iris_df.randomSplit([0.8, 0.2], seed=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCNKrP2PrZ2E"
      },
      "source": [
        "### Build cross-validation model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmeci33_rZ2E"
      },
      "source": [
        "#### Estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChVMZp0srZ2F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "1e402fb7-cd79-4aa3-ef86-b98506c286f0"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label\",smoothing=1.0, modelType=\"multinomial\")\n",
        "nb = nb.fit(train)\n",
        "pred = nb.transform(test)\n",
        "pred.select('species','label','prediction').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+----------+\n",
            "|   species|label|prediction|\n",
            "+----------+-----+----------+\n",
            "|    setosa|  2.0|       2.0|\n",
            "|    setosa|  2.0|       2.0|\n",
            "|    setosa|  2.0|       2.0|\n",
            "|    setosa|  2.0|       2.0|\n",
            "|    setosa|  2.0|       2.0|\n",
            "|    setosa|  2.0|       2.0|\n",
            "|    setosa|  2.0|       2.0|\n",
            "|    setosa|  2.0|       2.0|\n",
            "|versicolor|  0.0|       0.0|\n",
            "|    setosa|  2.0|       2.0|\n",
            "|    setosa|  2.0|       2.0|\n",
            "|versicolor|  0.0|       0.0|\n",
            "| virginica|  1.0|       1.0|\n",
            "|versicolor|  0.0|       0.0|\n",
            "|versicolor|  0.0|       0.0|\n",
            "|versicolor|  0.0|       0.0|\n",
            "| virginica|  1.0|       1.0|\n",
            "|versicolor|  0.0|       0.0|\n",
            "| virginica|  1.0|       0.0|\n",
            "| virginica|  1.0|       1.0|\n",
            "+----------+-----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgSa7j0eyUf_"
      },
      "source": [
        "#### Prediction accurary\n",
        "Four accuracy matrices are avaiable for this evaluator. \n",
        "* `f1`\n",
        "* `weightedPrecision`\n",
        "* `weightedRecall`\n",
        "* `accuracy`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3THw2nx0LOo"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "eval = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnWlxuQM647H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "42cf5851-0ef3-4cdc-a8b0-2330de1c8c34"
      },
      "source": [
        "# Accuracy\n",
        "acc = eval.evaluate(pred, {eval.metricName: \"accuracy\"})\n",
        "# acc = eval.setMetricName('accuracy').evaluate(pred)# another way to evaluate\n",
        "print(\"Accuracy: %.3f\" % acc)\n",
        "\n",
        "# Weighted Precision\n",
        "# weightedPrecision = eval.evaluate(pred, {eval.metricName: \"weightedPrecision\"})\n",
        "weightedPrecision = eval.setMetricName('weightedPrecision').evaluate(pred)\n",
        "print(\"Weighted Precision: %.3f\" % weightedPrecision)\n",
        "\n",
        "# weightedRecall \n",
        "# weightedRecall = eval.evaluate(pred, {eval.metricName: \"weightedRecall\"})\n",
        "weightedRecall= eval.setMetricName('weightedRecall').evaluate(pred)\n",
        "print(\"Weighted Recall: %.3f\" % weightedRecall)\n",
        "\n",
        "# f1\n",
        "# f1 = eval.evaluate(pred, {eval.metricName: \"f1\"})\n",
        "f1=eval.setMetricName('f1').evaluate(pred)\n",
        "print(\"f1: %.3f\" %f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.958\n",
            "Weighted Precision: 0.964\n",
            "Weighted Recall: 0.958\n",
            "f1: 0.958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQXBmQ46xVTE"
      },
      "source": [
        "### Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZswvqBfTxV1Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "3a8521ef-5524-4e45-d5ee-5292ced612a0"
      },
      "source": [
        "conf_mat = pred.select('label', 'prediction')\n",
        "conf_mat.rdd.zipWithIndex().countByKey()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {Row(label=0.0, prediction=0.0): 7,\n",
              "             Row(label=1.0, prediction=0.0): 1,\n",
              "             Row(label=1.0, prediction=1.0): 6,\n",
              "             Row(label=2.0, prediction=2.0): 10})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55gHWXtTXbi6"
      },
      "source": [
        "## Use MulticlassMetrics library under mllib ##   \n",
        "### Convert to RDD before using mllib ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjDxqsmKEM9U"
      },
      "source": [
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "predictionRDD = pred.select(['label', 'prediction']) \\\n",
        "                            .rdd.map(lambda line: (line[1], line[0]))\n",
        "metrics = MulticlassMetrics(predictionRDD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HobmTYWegyPH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "3e43890f-cfd4-4f66-a2cb-b3239c401522"
      },
      "source": [
        "# Confusion Matrix\n",
        "cm = metrics.confusionMatrix().toArray()\n",
        "print(\"Confusion Matrix:\")\n",
        "print(\"%10s %12s %12s %12s\" % (\"real\\pred\" ,\"predicted 0\", \"predicted 1\", \"predicted 2\"))\n",
        "for i in range (0,3):\n",
        "  print(\"real %2s\" % i, end='')\n",
        "  for j in range (0,3):\n",
        "    print(\"%12d\" % cm[i][j], end='')\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            " real\\pred  predicted 0  predicted 1  predicted 2\n",
            "real  0           7           0           0\n",
            "real  1           1           6           0\n",
            "real  2           0           0          10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtTR4WTtJR_a"
      },
      "source": [
        "# Define a function to evaluate each of the three labels, i.e., 0, 1, and 2\n",
        "def cr(label_in):\n",
        "  precision = metrics.precision(label=label_in)\n",
        "  recall = metrics.recall(label=label_in)\n",
        "  F1_Measure = metrics.fMeasure(label=label_in)\n",
        "  support = test.filter(test.label==label_in).count()\n",
        "  print(\"%10s %12.2f  %12.2f %12.2f %12d\" % \\\n",
        "          (label_in,precision, recall, F1_Measure, support))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TATAzG09aT9Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "8beee133-4bca-4edb-bba4-6fe54a9c9369"
      },
      "source": [
        "import numpy as np\n",
        "print(\"            Classification Report\")\n",
        "print(\"%10s %12s  %12s %12s %12s\"    % (\"label\",\"precision\",\"recall\",\"f1-score\",\"support\"))\n",
        "for i in np.arange(0.0, 3.0, 1.0):\n",
        "  cr(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Classification Report\n",
            "     label    precision        recall     f1-score      support\n",
            "       0.0         0.88          1.00         0.93            7\n",
            "       1.0         1.00          0.86         0.92            7\n",
            "       2.0         1.00          1.00         1.00           10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgGO1_nbyehT"
      },
      "source": [
        "## Extend the process with Grid search and crossover"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9yVH2O92hFq"
      },
      "source": [
        "### Build cross-validation model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ9h6yQZ2hFs"
      },
      "source": [
        "#### Estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSN65CY32hFt"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "naivebayes = NaiveBayes(featuresCol=\"features\", labelCol=\"label\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ITWgTBYrZ2G"
      },
      "source": [
        "#### Parameter grid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX3k_HxorZ2H"
      },
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "param_grid = ParamGridBuilder().\\\n",
        "    addGrid(naivebayes.smoothing, [0, 1, 2, 4, 8]).\\\n",
        "    build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok9NLj_HrZ2J"
      },
      "source": [
        "#### Evaluator\n",
        "There are three categories in the label column. Therefore, we use `MulticlassClassificationEvaluator`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeAT_VmCrZ2L"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMFpGyYYrZ2O"
      },
      "source": [
        "#### Build cross-validation model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb1e6G4BrZ2P"
      },
      "source": [
        "from pyspark.ml.tuning import CrossValidator\n",
        "crossvalidator = CrossValidator(estimator=naivebayes, estimatorParamMaps=param_grid, evaluator=evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFhjSuvErZ2Q"
      },
      "source": [
        "#### Fit cross-validation model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKxFSww9rZ2R"
      },
      "source": [
        "crossvalidation_mode = crossvalidator.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCtr0VAPrZ2T"
      },
      "source": [
        "#### Prediction on training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "189z-GbErZ2T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "fa438517-c95b-41bd-b704-53cc0bdc1920"
      },
      "source": [
        "pred_train = crossvalidation_mode.transform(train)\n",
        "pred_train.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+-------+-----+--------------------+--------------------+----------+\n",
            "|         features|species|label|       rawPrediction|         probability|prediction|\n",
            "+-----------------+-------+-----+--------------------+--------------------+----------+\n",
            "|[4.4,3.2,1.3,0.2]| setosa|  2.0|[-12.291171378989...|[0.19555929123370...|       2.0|\n",
            "|[4.5,2.3,1.3,0.3]| setosa|  2.0|[-11.142786320680...|[0.26949095780384...|       2.0|\n",
            "|[4.6,3.1,1.5,0.2]| setosa|  2.0|[-12.550742246764...|[0.21656037289160...|       2.0|\n",
            "|[4.6,3.2,1.4,0.2]| setosa|  2.0|[-12.592365024690...|[0.20052392100539...|       2.0|\n",
            "|[4.6,3.4,1.4,0.3]| setosa|  2.0|[-13.148463542368...|[0.19824085251800...|       2.0|\n",
            "+-----------------+-------+-----+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLqmRLICrZ2W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ba2e3283-f09d-4c9e-e7bc-ef35a8dc2a83"
      },
      "source": [
        "pred_test = crossvalidation_mode.transform(test)\n",
        "pred_test.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+-------+-----+--------------------+--------------------+----------+\n",
            "|         features|species|label|       rawPrediction|         probability|prediction|\n",
            "+-----------------+-------+-----+--------------------+--------------------+----------+\n",
            "|[4.3,3.0,1.1,0.1]| setosa|  2.0|[-11.402228667810...|[0.18240945200010...|       2.0|\n",
            "|[4.4,2.9,1.4,0.2]| setosa|  2.0|[-11.923306551010...|[0.22553075812617...|       2.0|\n",
            "|[4.4,3.0,1.3,0.2]| setosa|  2.0|[-11.964929328937...|[0.20930932928504...|       2.0|\n",
            "|[4.8,3.1,1.6,0.2]| setosa|  2.0|[-12.851935892465...|[0.22180002940740...|       2.0|\n",
            "|[5.0,3.3,1.4,0.2]| setosa|  2.0|[-13.114876846919...|[0.18601727933390...|       2.0|\n",
            "+-----------------+-------+-----+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXdy-xHGrZ2X"
      },
      "source": [
        "#### Best model from cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY15ZHtZrZ2Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb3afbb1-97e4-47f3-885e-faadc796ace8"
      },
      "source": [
        "print(\"The parameter smoothing has best value:\",\n",
        "      crossvalidation_mode.bestModel._java_obj.getSmoothing())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameter smoothing has best value: 8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYi7ZuTKrZ2Z"
      },
      "source": [
        "#### Prediction accurary\n",
        "Four accuracy matrices are avaiable for this evaluator. \n",
        "* `f1`\n",
        "* `weightedPrecision`\n",
        "* `weightedRecall`\n",
        "* `accuracy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDusHsIyrZ2a"
      },
      "source": [
        "##### Prediction accuracy on training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FwyIXX3rZ2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "357bf427-ad7d-4290-e251-3a561e3f76b3"
      },
      "source": [
        "print('training data (f1):', evaluator.setMetricName('f1').evaluate(pred_train), \"\\n\",\n",
        "     'training data (weightedPrecision): ', evaluator.setMetricName('weightedPrecision').evaluate(pred_train),\"\\n\",\n",
        "     'training data (weightedRecall): ', evaluator.setMetricName('weightedRecall').evaluate(pred_train),\"\\n\",\n",
        "     'training data (accuracy): ', evaluator.setMetricName('accuracy').evaluate(pred_train))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data (f1): 0.968236789665361 \n",
            " training data (weightedPrecision):  0.9689250225835592 \n",
            " training data (weightedRecall):  0.9682539682539681 \n",
            " training data (accuracy):  0.9682539682539683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktkYyjB4rZ2b"
      },
      "source": [
        "##### Prediction accuracy on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdIhidmDrZ2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "1e552449-5177-4803-efa7-fad7434cf42f"
      },
      "source": [
        "print('test data (f1):', evaluator.setMetricName('f1').evaluate(pred_test), \"\\n\",\n",
        "     'test data (weightedPrecision): ', evaluator.setMetricName('weightedPrecision').evaluate(pred_test),\"\\n\",\n",
        "     'test data (weightedRecall): ', evaluator.setMetricName('weightedRecall').evaluate(pred_test),\"\\n\",\n",
        "     'test data (accuracy): ', evaluator.setMetricName('accuracy').evaluate(pred_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test data (f1): 0.958119658119658 \n",
            " test data (weightedPrecision):  0.9635416666666667 \n",
            " test data (weightedRecall):  0.9583333333333334 \n",
            " test data (accuracy):  0.9583333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "318Hin-srZ2f"
      },
      "source": [
        "### Confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_K9fYJMrZ2f"
      },
      "source": [
        "#### Confusion matrix on training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIpYXCpNrZ2g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "c9c633f0-0ef7-4958-9fb6-d24fddc3b1b1"
      },
      "source": [
        "train_conf_mat = pred_train.select('label', 'prediction')\n",
        "train_conf_mat.rdd.zipWithIndex().countByKey()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {Row(label=0.0, prediction=0.0): 42,\n",
              "             Row(label=0.0, prediction=1.0): 1,\n",
              "             Row(label=1.0, prediction=0.0): 3,\n",
              "             Row(label=1.0, prediction=1.0): 40,\n",
              "             Row(label=2.0, prediction=2.0): 40})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2q6yolbrZ2i"
      },
      "source": [
        "#### Confusion matrix on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmjCbIj_rZ2j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "59d1f584-7726-4b8b-f5bd-9612c4857f5f"
      },
      "source": [
        "test_conf_mat = pred_test.select('label', 'prediction')\n",
        "test_conf_mat.rdd.zipWithIndex().countByKey()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {Row(label=0.0, prediction=0.0): 7,\n",
              "             Row(label=1.0, prediction=0.0): 1,\n",
              "             Row(label=1.0, prediction=1.0): 6,\n",
              "             Row(label=2.0, prediction=2.0): 10})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpX5Xr9qrZ2k"
      },
      "source": [
        "**From the confusion matrices on both training and test data, we can see that there are only a few mismatches between prediction and label values.**"
      ]
    }
  ]
}